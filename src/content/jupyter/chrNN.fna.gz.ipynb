{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromosome assemblies NN\n",
    "\n",
    "1. [https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/38p14_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/](https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "1. Coordinates did not correspond to the nuccore sequencce on ncbi site\n",
    "1. Test this version\n",
    "1. https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "from hashlib import sha256\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "inputChr = 24\n",
    "\n",
    "inputPath = 'C:\\\\Users\\\\creeperpandatrex\\\\Documents\\\\1000genomes\\\\DATA\\\\GCF000001405-38p14-assembly\\\\'\n",
    "\n",
    "inputFile = 'chr'+str(inputChr)+'.fna.gz'\n",
    "inputFile = 'chrY.fna.gz'\n",
    "inputFile = 'chr'+str(inputChr)+'.fna.gz'\n",
    "inputFile = 'chrX.fna.gz'\n",
    "\n",
    "myLocal = inputPath + 'awk_ID_symbol_start_end_chr_'+str(inputChr)\n",
    "\n",
    "# print(os.getenv('SEED'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "1. read the gz file using fasta2one(gzip.open(inputpath+inputFile, 'rt)) syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='C:\\\\Users\\\\creeperpandatrex\\\\Documents\\\\1000genomes\\\\DATA\\\\GCF000001405-38p14-assembly\\\\chrX.fna.gz' encoding='utf-8'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# my is a string of chromosome 'NN' fasta files with 80 char per line to fasta with 2 lines ONLY\n",
    "def fasta2one (myPath):\n",
    "    with myPath as file:\n",
    "        build = ''\n",
    "        print(myPath)\n",
    "        for i in file:\n",
    "            build += i.strip()\n",
    "        return build\n",
    "\n",
    "my = fasta2one(gzip.open(inputPath + inputFile, 'rt')) # 6.27.2024 __14__ minutes\n",
    "\n",
    "print(type(my)) # <class 'str'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "1. zgrep -P 'chromosome\\t22' GCF_000001405.40_GRCh38.p14_feature_table.txt > grep_minusP_chr_backslash_t_22 \n",
    "1. PIPE wc -l => 4357\n",
    "1. grep gene grep_minusP_chr_backslash_t_22 > grep_gene_minusP_chr22\n",
    "1. PIPE wc -l  => 896\n",
    "1. awk -F'\\t' '{print$16\"\\t\"$15\"\\t\"$8\"\\t\"$9}' grep_gene_minusP_chr22 > awk_ID_symbol_start_end_chr_22\n",
    "1. read chrNUMB.fna.gz, output.strip(); output as string\n",
    "1. read file:///C:/Users/creeperpandatrex/Documents/1000genomes/DATA/38.p14/awk_ID_symbol_start_end_chr_22, \n",
    "1. as list per element/line [id, symbol, start, end]\n",
    "1. build a set to eliminate duplicates\n",
    "1. with both files \n",
    "    1. read [id,symbol,start,end] from one file\n",
    "    1. extract sequence using start, end+1, end-start, with counter equal to start\n",
    "    1. hash the built sequence\n",
    "    1. save idSymbol-map-to-idSymbolHash and idSymbolHash-map-to-buildSeqHash (maybe two or three)\n",
    "    1. save as [{ 'idSymbHash': 'buildSeqHash'}, {}, {}, ....]\n",
    "1. Upload sequence\n",
    "1. done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creeperpandatrex\\Documents\\1000genomes\\DATA\\GCF000001405-38p14-assembly\\awk_ID_symbol_start_end_chr_24\n",
      "2512\n",
      "2375\n",
      "('107985659', 'LOC107985659', '52583989', '52589040')\n",
      "('6845', 'VAMP7', '155881345', '155943769')\n",
      "('100125392', 'TIPINP1', '53455216', '53457148')\n",
      "('100302153', 'MIR1298', '114715233', '114715344')\n",
      "('100873985', 'MED14OS', '40735690', '40738698')\n",
      "('642546', 'HK2P1', '80569430', '80575038')\n",
      "('100129818', 'TUBAP6', '115424045', '115425694')\n",
      "('100873568', 'RNA5SP517', '146427456', '146427572')\n",
      "('7317', 'UBA1', '47190847', '47215128')\n",
      "('101927830', 'LOC101927830', '155347137', '155374174')\n"
     ]
    }
   ],
   "source": [
    "# tmp list from set of grep_gene to remove duplicates\n",
    "# myLocal = inputPath + 'awk_ID_symbol_start_end_chr_2'\n",
    "def idSymbolBuildSet(myPath):\n",
    "    print(myPath)\n",
    "    myList = []\n",
    "    obj = open(myPath, 'r')\n",
    "    for i in obj:\n",
    "        local = i.split()\n",
    "        myList.append(local)\n",
    "        local = []\n",
    "    print(len(myList)) # 3362 total, after removal 2958\n",
    "    mySet = set(tuple(i) for i in myList) # remove duplicates \n",
    "    set2list = list(mySet)\n",
    "    return set2list\n",
    "\n",
    "tmp = idSymbolBuildSet(myLocal)\n",
    "print(len(tmp))\n",
    "\n",
    "myRange = 10\n",
    "counter = 0\n",
    "for i in range(myRange):\n",
    "    print(tmp[counter])\n",
    "    counter += 1\n",
    "\n",
    "# https://stackoverflow.com/questions/26783326/how-to-make-a-set-of-listslist\n",
    "# >>> l = [[1, 2, 3], [2, 4, 5], [1, 2, 3], [2, 4, 5]]\n",
    "# >>> set(tuple(i) for i in l)\n",
    "# {(1, 2, 3), (2, 4, 5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two files\n",
    "1. chr22 as string my\n",
    "1. idSymbol with start and end coordinates tmp is a list of 4 tuples\n",
    "1. tmp = [ (id,symbol,start,end), (), (), (), ......]\n",
    "1. hash all four, meaning each tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "1. processing is the    return [myListOfDicMap, myListIdSymbSeqHash]\n",
    "1. myListOfDicMap is [ {'fourTuple': '(id, symb, start, end)', 'fourTupleHash':'XXXXXXX'}, {}, {}, .....]\n",
    "1. myListIdSymbSeqHash is [ {fourTupleHash : geneSeqHash}, {'XXXXX' : 'XXXXXXX' }, {'XX':'XX'}, .... ]\n",
    "1. Process chromosome 22 3.2 seconds\n",
    "1. Compress and Write to disk object: processing []\n",
    "1. Pending sanity test with 5' 3' primers from each gene to confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving into a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processChrWithIdSymbolSanityCheck():\n",
    "    myListOfDicMap = []\n",
    "    myListIdSymbSeqHash = []\n",
    "    sanityCheck = []\n",
    "    primer = ''\n",
    "    for i in range(len(tmp)):\n",
    "        localArray = []\n",
    "        mySeed = os.getenv('SEED')\n",
    "        myDicMap = {}\n",
    "        myDicTupleSeqHash = {}\n",
    "        localTuple = tmp[i]\n",
    "        localTupleHash = sha256((convertTuple(localTuple) + mySeed).encode()).hexdigest()\n",
    "        myDicMap.update({'fourTuple':localTuple, 'fourTupleHash':localTupleHash})\n",
    "        myListOfDicMap.append(myDicMap)\n",
    "        seqHash = buildSeqHash(localTuple, mySeed)\n",
    "        myDicTupleSeqHash.update( {localTupleHash: seqHash[0] })\n",
    "        # print(type(seqHash[1]))\n",
    "        seqSize = len(seqHash[1])\n",
    "        print('>'+str(localTuple)+'\\t'+str(seqSize)+'\\n')\n",
    "        primer += '>'+str(localTuple)+'\\t'+str(seqSize)+'\\n'\n",
    "        first = ''\n",
    "        last = ''\n",
    "        counter = 0\n",
    "        if len(seqHash[1]) > 40:\n",
    "            for j in range(40):\n",
    "                first += seqHash[1][counter]\n",
    "                counter += 1\n",
    "            localArray.append(first)\n",
    "        counter =  -40\n",
    "        if len(seqHash[1]) > 40:\n",
    "            for k in range(40):\n",
    "                last += (seqHash[1][counter])\n",
    "                counter += 1\n",
    "            localArray.append(last)\n",
    "        # print(first+'..'+len(seqHash)+'..'+last)   #### PRINT\n",
    "        # print(first+'....'+last)   #########  PRINT\n",
    "        primer += first+'....'+last+'\\n'\n",
    "        sanityCheck.append(seqHash[1])\n",
    "        myListIdSymbSeqHash.append(myDicTupleSeqHash)\n",
    "    return [myListOfDicMap, myListIdSymbSeqHash, sanityCheck, primer]    \n",
    "    \n",
    "def print2file (myPath, result):\n",
    "    out = open(myPath, 'w')\n",
    "    out.write(result) # it must be a string\n",
    "\n",
    "def buildSeqHash(tuple, mySeed):\n",
    "    mySeq = ''\n",
    "    id,symb,start,end = tuple\n",
    "    start = int(start) \n",
    "    end = int(end)  \n",
    "    counter = start + 80\n",
    "    for i in range(end - start + 1):\n",
    "        mySeq += my[counter]\n",
    "        counter += 1\n",
    "    mySeqHash = sha256(((mySeq+mySeed)).encode()).hexdigest()\n",
    "    return [mySeqHash, mySeq] # both string\n",
    "\n",
    "\n",
    "# print(buildSeq(processing[0]['fourTuple']))\n",
    "        \n",
    "def convertTuple(tup):\n",
    "    str = ''.join(tup)\n",
    "    return str\n",
    "\n",
    "processing = processChrWithIdSymbolSanityCheck()\n",
    "print(len(processing)) # 4; 2 minutes\n",
    "\n",
    "\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(10):\n",
    "#     print(processing[0][counter]) # labelmap list of dics json\n",
    "#     print(processing[1][counter]) # labelseqhash list of dics json\n",
    "#     print(processing[2][counter]) # gene sequence in array\n",
    "#     print(processing[3][counter]) # primer string\n",
    "#     counter += 1\n",
    "\n",
    "# {'fourTuple': ('105373037', 'LOC105373037', '40555177', '40564466'), 'fourTupleHash': 'b1514454efb34d796e695624a103c9a5b4727f09df995728389633123747a653'}\n",
    "# {'fourTuple': ('339685', 'LOC339685', '47345571', '47373541'), 'fourTupleHash': 'b5c159d961591a4e83f3726b4933d92890392c769b28c825c4bc0b2d05bca5d8'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "1. processing is the     return [myListOfDicMap, myListIdSymbSeqHash, sanityCheck, primer]    \n",
    "1. myListOfDicMap is [ {'fourTuple': '(id, symb, start, end)', 'fourTupleHash':'XXXXXXX'}, {}, {}, .....]\n",
    "1. extension: `labelmap` list of dics of json\n",
    "1. myListIdSymbSeqHash is [ {fourTupleHash : geneSeqHash}, {'XXXXX' : 'XXXXXXX' }, {'XX':'XX'}, .... ]\n",
    "1. extension: `labelseqhash` list of dics of json\n",
    "1. sanityCheck, extension: gene sequence in array\n",
    "1. primer: text file two lines, first line a tuple(id, symbol, start, end), second line 5'3' primers of gene genomic seq\n",
    "1. Process chromosome 21: ___ seconds\n",
    "1. Compress and Write to disk object: processing []\n",
    "1. Pending sanity test with 5' 3' primers from each gene to confirm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creeperpandatrex\\Documents\\1000genomes\\DATA\\GCF000001405-38p14-assembly\\chrX.fna.gz\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# print2file(inputPath + inputFile + \".labelmap\", json.dumps(dict2hash(globalDictionary)[0]))\n",
    "# print2file(inputPath + inputFile + \".labelseqhash\", json.dumps(dict2hash(globalDictionary)[1]))\n",
    "result = processing\n",
    "\n",
    "def print2file (myPath, result):\n",
    "    out = open(myPath, 'w')\n",
    "    out.write(result) # it must be a string\n",
    "\n",
    "def print2gz (myPath, result, addExt):\n",
    "   with gzip.open(myPath + addExt, 'w') as f:\n",
    "    f.write((json.dumps(result)).encode()) # no decode() since it is a str already\n",
    "\n",
    "print(inputPath+inputFile)\n",
    "print2gz(inputPath + inputFile, result[0], '.labelmap.gz')\n",
    "print2gz(inputPath + inputFile, result[1], '.labelseqhash.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n",
      "C:\\Users\\creeperpandatrex\\Documents\\1000genomes\\DATA\\GCF000001405-38p14-assembly\\chrX.fna.gz\n"
     ]
    }
   ],
   "source": [
    "### this is SANITY CHECK  \n",
    "### processing[0] is .labelmap list of dics json\n",
    "### processing[1] is  .labelseqhash list of dics json\n",
    "### processing[2] is .fna.gene array of sequences from gene\n",
    "### processing[3] is .primer string 2 lines \n",
    "\n",
    "print(len(processing[2])) # 2958\n",
    "\n",
    "print(inputPath+inputFile)\n",
    "\n",
    "print2file(inputPath+inputFile+'.primer', processing[3])\n",
    "# print2file(inputPath+inputFile+'.fna.gene', json.dumps(processing[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# {'fourTuple': ('105373037', 'LOC105373037', '40555177', '40564466'), 'fourTupleHash': 'b1514454efb34d796e695624a103c9a5b4727f09df995728389633123747a653'}\n",
    "# {'fourTuple': ('339685', 'LOC339685', '47345571', '47373541'), 'fourTupleHash': 'b5c159d961591a4e83f3726b4933d92890392c769b28c825c4bc0b2d05bca5d8'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking genome sequences between primers\n",
    "### this is SANITY CHECK  \n",
    "1. processing[0] is .labelmap\n",
    "1. processing[1] is  .labelseqhash\n",
    "1. processing[2] is .fna.gene\n",
    "1. processing[3] is .primer\n",
    "1. sanity check with processChrWithIdSymbolSanityCheck(): primers good pending \n",
    "double check hashes\n",
    "1. not sanity check with processChrWithIdSymbol(): hashesh wrong and not checked\n",
    "\n",
    "\n",
    "\n",
    "### Pending\n",
    "1. 6.23.2024\n",
    "1. .primer is two lines: first line with > and tuple with id, symbol, start, end\n",
    "1. .primer second line with gene 5'primer 3'end primer \n",
    "1. direction based in reference sequence\n",
    "1. Checked \n",
    "```\n",
    " 19 >('5902', 'RANBP1', '20116104', '20127355')     11252\n",
    "     20 ACTGTCCATAGAGGGGTCACCACGTCGGCCACTCGTGTTA....CATCAAAAATAGTGAATAAAAAACACATTTGGAACCTGGG\n",
    "  \n",
    "```\n",
    "And it looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n"
     ]
    }
   ],
   "source": [
    "print(len(processing[2])) # 2958"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fox-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
