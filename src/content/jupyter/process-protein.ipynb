{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process protein sequences\n",
    "\n",
    "# Summary process-protein 6.14.2024\n",
    "1. read from gz\n",
    "1. convert to non-fasta format: firstline definition, secondline aa\n",
    "1. hashes\n",
    "1. save labelMap and labelSeqHash as gz\n",
    "1. find duplicates and count them\n",
    "    1. convert to a set() to include only unique seqHash\n",
    "    1. convert set to a list of unique seqHash to give index order\n",
    "    1. count duplicates and add to a list of numOfDups same length as the unique seqHash\n",
    "    1. loop original labelseqhash to read unique seqHash list in parallel to numOfDups list to populate it based on same index.\n",
    "    1. create a list of dics (newList) where each dictionary element is of type{'XXXXXX' : 8} key/seqHash and value/number-of-duplicates\n",
    "    1. Test by running def findDuplicates(obj, item) : the obj is result[1] containing labelhash and seqHash k/v pairs \n",
    "    1. and\n",
    "    1. findDup(obj, item) obj is newList and uses dic.get(item) to find the key/value pair which is the seqHash/numberof duplicates. \n",
    "1. Sorting PENDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "from hashlib import sha256\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "fastaProtein = [ {'label': '>NP_000005.3 alpha-2-macroglobulin isoform a precursor [Homo sapiens]', 'seq': 'MGKNKLLHPSLVLLLLVLLPTDASVSGKPQYMVLVPSLLHTETTEKGCVLLSYLNETVTVSASLESVRGNRSLFTDLEAENDVLHCVAFAVPKSSSNEEVMFLTVQVKGPTQEFKKRTTVMVKNEDSLVFVQTDKSIYKPGQTVKFRVVSMDENFHPLNELIPLVYIQDPKGNRIAQWQSFQLEGGLKQFSFPLSSEPFQGSYKVVVQKKSGGRTEHPFTVEEFVLPKFEVQVTVPKIITILEEEMNVSVCGLYTYGKPVPGHVTVSICRKYSDASDCHGEDSQAFCEKFSGQLNSHGCFYQQVKTKVFQLKRKEYEMKLHTEAQIQEEGTVVELTGRQSSEITRTITKLSFVKVDSHFRQGIPFFGQVRLVDGKGVPIPNKVIFIRGNEANYYSNATTDEHGLVQFSINTTNVMGTSLTVRVNYKDRSPCYGYQWVSEEHEEAHHTAYLVFSPSKSFVHLEPMSHELPCGHTQTVQAHYILNGGTLLGLKKLSFYYLIMAKGGIVRTGTHGLLVKQEDMKGHFSISIPVKSDIAPVARLLIYAVLPTGDVIGDSAKYDVENCLANKVDLSFSPSQSLPASHAHLRVTAAPQSVCALRAVDQSVLLMKPDAELSASSVYNLLPEKDLTGFPGPLNDQDNEDCINRHNVYINGITYTPVSSTNEKDMYSFLEDMGLKAFTNSKIRKPKMCPQLQQYEMHGPEGLRVGFYESDVMGRGHARLVHVEEPHTETVRKYFPETWIWDLVVVNSAGVAEVGVTVPDTITEWKAGAFCLSEDAGLGISSTASLRAFQPFFVELTMPYSVIRGEAFTLKATVLNYLPKCIRVSVQLEASPAFLAVPVEKEQAPHCICANGRQTVSWAVTPKSLGNVNFTVSAEALESQELCGTEVPSVPEHGRKDTVIKPLLVEPEGLEKETTFNSLLCPSGGEVSEELSLKLPPNVVEESARASVSVLGDILGSAMQNTQNLLQMPYGCGEQNMVLFAPNIYVLDYLNETQQLTPEIKSKAIGYLNTGYQRQLNYKHYDGSYSTFGERYGRNQGNTWLTAFVLKTFAQARAYIFIDEAHITQALIWLSQRQKDNGCFRSSGSLLNNAIKGGVEDEVTLSAYITIALLEIPLTVTHPVVRNALFCLESAWKTAQEGDHGSHVYTKALLAYAFALAGNQDKRKEVLKSLNEEAVKKDNSVHWERPQKPKAPVGHFYEPQAPSAEVEMTSYVLLAYLTAQPAPTSEDLTSATNIVKWITKQQNAQGGFSSTQDTVVALHALSKYGAATFTRTGKAAQVTIQSSGTFSSKFQVDNNNRLLLQQVSLPELPGEYSMKVTGEGCVYLQTSLKYNILPEKEEFPFALGVQTLPQTCDEPKAHTSFQISLSVSYTGSRSASNMAIVDVKMVSGFIPLKPTVKMLERSNHVSRTEVSSNHVLIYLDKVSNQTLSLFFTVLQDVPVRDLKPAIVKVYDYYETDEFAIAEYNAPCSKDLGNA'}, {'label': '>NP_000006.2 arylamine N-acetyltransferase 2 [Homo sapiens]', 'seq': 'MDIEAYFERIGYKNSRNKLDLETLTDILEHQIRAVPFENLNMHCGQAMELGLEAIFDHIVRRNRGGWCLQVNQLLYWALTTIGFQTTMLGGYFYIPPVNKYSTGMVHLLLQVTIDGRNYIVDAGSGSSSQMWQPLELISGKDQPQVPCIFCLTEERGIWYLDQIRREQYITNKEFLNSHLLPKKKHQKIYLFTLEPRTIEDFESMNTYLQTSPTSSFITTSFCSLQTPEGVYCLVGFILTYRKFNYKDNTDLVEFKTLTEEEVEEVLRNIFKISLGRNLVPKPGDGSLTI'}, {'label': '>YP_003024037.1 NADH dehydrogenase subunit 6 (mitochondrion) [Homo sapiens]', 'seq': 'MMYALFLLSVGLVMGFVGFSSKPSPIYGGLVLIVSGVVGCVIILNFGGGYMGLMVFLIYLGGMMVVFGYTTAMAIEEYPEAWGSGVEVLVSVLVGLAMEVGLVLWVKEYDGVVVVVNFNSVGSWMIYEGEGSGLIREDPIGAGALYDYGRWLVVVTGWTLFVGVYIVIEIARGN'}, {'label': '>YP_003024038.1 cytochrome b (mitochondrion) [Homo sapiens]', 'seq': 'MTPMRKTNPLMKLINHSFIDLPTPSNISAWWNFGSLLGACLILQITTGLFLAMHYSPDASTAFSSIAHITRDVNYGWIIRYLHANGASMFFICLFLHIGRGLYYGSFLYSETWNIGIILLLATMATAFMGYVLPWGQMSFWGATVITNLLSAIPYIGTDLVQWIWGGYSVDSPTLTRFFTFHFILPFIIAALATLHLLFLHETGSNNPLGITSHSDKITFHPYYTIKDALGLLLFLLSLMTLTLFSPDLLGDPDNYTLANPLNTPPHIKPEWYFLFAYTILRSVPNKLGGVLALLLSILILAMIPILHMSKQQSMMFRPLSQSLYWLLAADLLILTWIGGQPVSYPFTIIGQVASVLYFTTILILMPTISLIENKMLKWA'}]\n",
    "inputPath = 'C:\\\\Users\\\\creeperpandatrex\\\\Documents\\\\1000genomes\\\\DATA\\\\38.p14\\\\'\n",
    "inputFile = 'GCF_000001405.40_GRCh38.p14_protein.faa.gz'\n",
    "\n",
    "# print(os.getenv('SEED'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta2one (myPath):\n",
    "    with myPath as file:\n",
    "        countAngle = 0\n",
    "        countNoAngle = 0\n",
    "        fastaArrDics = []\n",
    "        currObj = {\"label\":'', \"seq\":''}\n",
    "        prevObj = {\"label\":'', \"seq\":''}\n",
    "        currSeq = \"\"\n",
    "        for line in file:\n",
    "            if line[0]  == '>':\n",
    "                countAngle += 1\n",
    "                currSeq = \"\"\n",
    "                prevObj = currObj\n",
    "                currObj = {\"label\":'', \"seq\":''}\n",
    "                currObj[\"label\"] = line.strip()\n",
    "                if countAngle != 1:\n",
    "                    fastaArrDics.append(prevObj)\n",
    "            else:\n",
    "                countNoAngle += 1\n",
    "                currSeq += line.strip()\n",
    "                currObj.update({\"seq\": currSeq}) \n",
    "        fastaArrDics.append(currObj)\n",
    "        # return [len(fastaArrDics), prevObj, currObj, countNoAngle + countAngle]\n",
    "        # return [len(fastaArrDics), fastaArrDics[0], fastaArrDics[1], fastaArrDics[-2], fastaArrDics[-1]]\n",
    "        return fastaArrDics\n",
    "\n",
    "# globalDictionary = fasta2one(gzip.open(inputFile, 'rt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save protein in non fasta format: two lines, definition/aminoacid sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print2file (myPath, result):\n",
    "    out = open(myPath, 'w')\n",
    "    out.write(result) # it must be a string\n",
    "\n",
    "globalDictionary = fasta2one(gzip.open(inputPath + inputFile, 'rt'))\n",
    "\n",
    "print2file(inputPath + inputFile + '.nonfasta', json.dumps(globalDictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def dict2hash (obj):\n",
    "    listDicLabelHash = []\n",
    "    listDicLabelHashSeqHash = []\n",
    "    for item in obj:\n",
    "        labelHash = sha256((item['label'] + os.getenv('SEED')).encode()).hexdigest()\n",
    "        seqHash = sha256((item['seq'] + os.getenv('SEED')).encode()).hexdigest()\n",
    "        print(item['label'] + '\\t' + labelHash)\n",
    "        print(labelHash + '\\t' + seqHash)\n",
    "        \n",
    "\n",
    "dict2hash(fastaProtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creeperpandatrex\\Documents\\1000genomes\\DATA\\38.p14\\\n",
      "GCF_000001405.40_GRCh38.p14_protein.faa.gz\n",
      "136194\n",
      "136194\n"
     ]
    }
   ],
   "source": [
    "# All data\n",
    "def dict2hash (obj):\n",
    "    listDicLabelHash = []\n",
    "    listDicLabelHashSeqHash = []\n",
    "    for item in obj:\n",
    "        labelHash = sha256((item['label'] + os.getenv('SEED')).encode()).hexdigest()\n",
    "        seqHash = sha256((item['seq'] + os.getenv('SEED')).encode()).hexdigest()\n",
    "        # print(item['label'] + '\\t' + labelHash)\n",
    "        # print(labelHash + '\\t' + seqHash)\n",
    "        labelMap = {'label': item['label'], 'labelHash': labelHash}\n",
    "        currObj = {'labelHash': labelHash, 'seqHash': seqHash}\n",
    "        listDicLabelHash.append(labelMap)\n",
    "        listDicLabelHashSeqHash.append(currObj)\n",
    "    return [listDicLabelHash, listDicLabelHashSeqHash]\n",
    "\n",
    "# dict2hash(fastaProtein)\n",
    "    \n",
    "print(inputPath)\n",
    "print(inputFile)\n",
    "\n",
    "print2file(inputPath + inputFile + \".labelmap\", json.dumps(dict2hash(globalDictionary)[0]))\n",
    "print2file(inputPath + inputFile + \".labelseqhash\", json.dumps(dict2hash(globalDictionary)[1]))\n",
    "\n",
    "result = dict2hash(globalDictionary)\n",
    "print(len(result[0]))\n",
    "print(len(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to file after compressing\n",
    "1. https://docs.python.org/3/library/gzip.html#examples-of-usage\n",
    "1. https://stackoverflow.com/questions/66250471/compresing-large-files-with-gzip-in-python\n",
    "\n",
    "## Compressing options: compress a list of dictionaries, compress a saved file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result : it contains an array of 2 elements: labelmap and labelseqhash\n",
    "\n",
    "```\n",
    "BLOCK_SIZE = 8192\n",
    "\n",
    "with open(myfile, \"rb\") as f_in, gzip.open(output_file, 'wb') as f_out:\n",
    "    while True:\n",
    "        content = f_in.read(BLOCK_SIZE)\n",
    "        if not content:\n",
    "            break\n",
    "        f_out.write(content)\n",
    "\n",
    "import gzip\n",
    "with gzip.open('/home/joe/file.txt.gz', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "import gzip\n",
    "content = b\"Lots of content here\"\n",
    "with gzip.open('/home/joe/file.txt.gz', 'wb') as f:\n",
    "    f.write(content)\n",
    "\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "with open('/home/joe/file.txt', 'rb') as f_in:\n",
    "    with gzip.open('/home/joe/file.txt.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "Example of how to GZIP compress a binary string:\n",
    "\n",
    "import gzip\n",
    "s_in = b\"Lots of content here\"\n",
    "s_out = gzip.compress(s_in)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(inputPath+inputFile+'.WB', 'wb') as f:\n",
    "    # f.write(json.dumps(result[0]))\n",
    "    f.write((json.dumps(result[0])).encode())\n",
    "\n",
    "with gzip.open(inputPath+inputFile+'.NOB', 'w') as f:\n",
    "    # f.write(json.dumps(result[0])) # list object is not a str\n",
    "    f.write((json.dumps(result[0])).encode()) # no decode() since it is a str already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creeperpandatrex@creepypandatrex MINGW64 ~/Documents/1000genomes/DATA/38.p14\n",
    "\n",
    "1. $ diff GCF_000001405.40_GRCh38.p14_protein.faa.WB GCF_000001405.40_GRCh38.p14_protein.faa.NOB\n",
    "1. Binary files GCF_000001405.40_GRCh38.p14_protein.faa.WB and GCF_000001405.40_GRCh38.p14_protein.faa.NOB  ```differ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save labelMap and labelSeqHash in compressed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# print2file(inputPath + inputFile + \".labelmap\", json.dumps(dict2hash(globalDictionary)[0]))\n",
    "# print2file(inputPath + inputFile + \".labelseqhash\", json.dumps(dict2hash(globalDictionary)[1]))\n",
    "\n",
    "def print2gz (myPath, result, addExt):\n",
    "   with gzip.open(myPath + addExt, 'w') as f:\n",
    "    f.write((json.dumps(result)).encode()) # no decode() since it is a str already\n",
    "\n",
    "print2gz(inputPath + inputFile, result[0], '.labelmap.gz')\n",
    "print2gz(inputPath + inputFile, result[1], '.labelseqhash.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In labelseqhash.gz\n",
    "1. Find sequence duplicates and count them.\n",
    "\n",
    "## Do statistics and save unique sequences into a file: \n",
    "1. One unique sequence to many labels/names with > char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#          labelmap    labeseqhash\n",
    "print(len(result[0]), len(result[1]))\n",
    "\n",
    "labelSeqHashPartial = [\n",
    "     {\"labelHash\": \"87eecab07dd6bbe71a3205767544365c513b6a9a2e5492c066582ccc4f7b0f58\", \"seqHash\": \"df32ee41d17e99fbae8a7b983e4a0f75cc288f2c4aca5d9d783a7598212c2546\"}, {\"labelHash\": \"f3fd5d36fc2cc34c02fa81d61a7bea5c02f2eb9ab02f2d0fd0a0fe09cb56f9e4\", \"seqHash\": \"8889a919f2537b3c7e87d36ef6baf37f5eca22e6e2b29bb6e2d017aced2a2777\"}, {\"labelHash\": \"b7554290ad15c0b939e7cef993be2bd8e845763fdd31ca14cb9d4d55ea7f1587\", \"seqHash\": \"c6a35324b6fe560f3e1bc1c4df4aaebf9d53f8c0c034da0e7f98a9041d31b5dc\"}, {\"labelHash\": \"fc588a8606e3ecb6c848f06a0aa8db87bdf2f8522c73993a34fc7c81f449f112\", \"seqHash\": \"45075f7ccf617e0af6d435f1799c003ddaa7cc915683a265958551a1a519b262\"}, {\"labelHash\": \"493e573302b81fef363a1e4f01de0232f89139ed8da63df5f31d695d15c1c8dd\", \"seqHash\": \"45075f7ccf617e0af6d435f1799c003ddaa7cc915683a265958551a1a519b262\"}, {\"labelHash\": \"aa488e6c8dd16fd769848b36fb65284960573f0ae4023cf17cfd79e0826cd4df\", \"seqHash\": \"f897dd2f861cba0dd3f9a5215c0b3a4f6efae55b9ec74f93bffc8f418b1dead2\"}\n",
    "]\n",
    "\n",
    "item = '8889a919f2537b3c7e87d36ef6baf37f5eca22e6e2b29bb6e2d017aced2a2777'\n",
    "item2 = '87eecab07dd6bbe71a3205767544365c513b6a9a2e5492c066582ccc4f7b0f58'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in result[1]:\n",
    "    if item == i['seqHash']:\n",
    "        print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#          labelmap    labelseqhash\n",
    "print(len(result[0]), len(result[1]))\n",
    "\n",
    "labelSeqHashPartial = [\n",
    "     {\"labelHash\": \"87eecab07dd6bbe71a3205767544365c513b6a9a2e5492c066582ccc4f7b0f58\", \"seqHash\": \"df32ee41d17e99fbae8a7b983e4a0f75cc288f2c4aca5d9d783a7598212c2546\"}, {\"labelHash\": \"f3fd5d36fc2cc34c02fa81d61a7bea5c02f2eb9ab02f2d0fd0a0fe09cb56f9e4\", \"seqHash\": \"8889a919f2537b3c7e87d36ef6baf37f5eca22e6e2b29bb6e2d017aced2a2777\"}, {\"labelHash\": \"b7554290ad15c0b939e7cef993be2bd8e845763fdd31ca14cb9d4d55ea7f1587\", \"seqHash\": \"c6a35324b6fe560f3e1bc1c4df4aaebf9d53f8c0c034da0e7f98a9041d31b5dc\"}, {\"labelHash\": \"fc588a8606e3ecb6c848f06a0aa8db87bdf2f8522c73993a34fc7c81f449f112\", \"seqHash\": \"45075f7ccf617e0af6d435f1799c003ddaa7cc915683a265958551a1a519b262\"}, {\"labelHash\": \"493e573302b81fef363a1e4f01de0232f89139ed8da63df5f31d695d15c1c8dd\", \"seqHash\": \"45075f7ccf617e0af6d435f1799c003ddaa7cc915683a265958551a1a519b262\"}, {\"labelHash\": \"aa488e6c8dd16fd769848b36fb65284960573f0ae4023cf17cfd79e0826cd4df\", \"seqHash\": \"f897dd2f861cba0dd3f9a5215c0b3a4f6efae55b9ec74f93bffc8f418b1dead2\"}\n",
    "]\n",
    "\n",
    "item = '8889a919f2537b3c7e87d36ef6baf37f5eca22e6e2b29bb6e2d017aced2a2777'\n",
    "\n",
    "\n",
    "# for i in result[1]:\n",
    "#     if item == i['seqHash']:\n",
    "#         print(i)\n",
    "    \n",
    "# Set unordered, no duplicates\n",
    "mySetUniqueSeqHash = set()\n",
    "for i in result[1]:\n",
    "    mySetUniqueSeqHash.add(i['seqHash'])\n",
    "print(len(mySetUniqueSeqHash)) # 89832\n",
    "print(item in mySetUniqueSeqHash) # True\n",
    "\n",
    "# build a list of dics with key:seqHash value:[one, two, three, etc labels]\n",
    "\n",
    "listOfUnique = list(mySetUniqueSeqHash) # 89832\n",
    "print(len(listOfUnique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89832\n"
     ]
    }
   ],
   "source": [
    "def convert(mySet):\n",
    "    return list(map(lambda x: x, mySet))\n",
    "\n",
    "# Driver function\n",
    "listOfUniqueMap = convert(mySetUniqueSeqHash)\n",
    "print(len(listOfUniqueMap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89832\n"
     ]
    }
   ],
   "source": [
    "# unique seqHash as a list.\n",
    "# for each item in result[1]:labelHash and seqHash, \n",
    "# unique seqHash from list to dictionary\n",
    "listOfDicsOfDups = []\n",
    "for i in listOfUnique:\n",
    "    dicsOfDups = {}\n",
    "    dicsOfDups.update({i : []})\n",
    "    listOfDicsOfDups.append(dicsOfDups)\n",
    "\n",
    "print(len(listOfDicsOfDups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now append labels and/or labelhash to dics value array\n",
    "def findIndex(item):\n",
    "    myIdx = listOfUnique.index(item)\n",
    "    # print(myIdx)\n",
    "    return myIdx\n",
    "\n",
    "print(listOfUnique.index('df32ee41d17e99fbae8a7b983e4a0f75cc288f2c4aca5d9d783a7598212c2546'))\n",
    "# position 40220\n",
    "numofDups = [0]*len(listOfUnique)\n",
    "counter = 0\n",
    "for i in result[1]:\n",
    "    findIdx = findIndex(i['seqHash'])\n",
    "    counter += 1\n",
    "    print('--------------- ', counter)\n",
    "    prevValue = numofDups[findIdx]\n",
    "    numofDups[findIdx] = prevValue + 1\n",
    "    prevValue = 0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89832\n",
      "89832\n",
      "1\n",
      "{'7930b7752c9b48d6cf08d8fd011db75fe8f5e750121a058a632ce3f9df44d5c0': []}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(len(numofDups))\n",
    "print(len(listOfDicsOfDups)) # [{i:[]},......]\n",
    "\n",
    "print(numofDups[0])\n",
    "print(listOfDicsOfDups[0])\n",
    "print(listOfDicsOfDups[0].get('7930b7752c9b48d6cf08d8fd011db75fe8f5e750121a058a632ce3f9df44d5c0'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newList: key: seqHash, value: number of duplicates\n",
    "## algorithm from process-protein ipynb\n",
    "1. cell 61: from result[0] labelMap result[1] labelseqHash\n",
    "1. from result[1] loop dictionary['seqHash'] add to a set\n",
    "1. set() does not accept duplicates, but it is unordered\n",
    "1. mySetUniqueSeqHash set 89832\n",
    "1. convert the set to list by list(mySet) to provide an index order\n",
    "1. listOfUnique 89832\n",
    "1. cell 64: create a list of dics duplicated as tuple('seqHash': 'xxxx', 'numOfDups': 19)\n",
    "1. or\n",
    "1. as {'XXXXXX': 19}\n",
    "1. or\n",
    "1. as {'XXXXX\" : []} to be able to add multiple label names hashes\n",
    "1. I decided for {'XXXXX': 19}\n",
    "1. listOfDicsOfDups\n",
    "1. cell 65: create a parallel list same length as listOfUnique and populate with zeros or None's otherwise it will complaint about adding to index out of bounds\n",
    "1. count number of duplicates by looping result[1] and adding one at the findIndex(i['seqHash']) in numOfDups list\n",
    "1. Finally, parallel loop listOfDicsOfDups and numOfDups to create a dic element type {'XXXXXXX': 3} total newList 89832\n",
    "1. Pending to confirm the correct mapping of seqHash to number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89832\n",
      "{'7930b7752c9b48d6cf08d8fd011db75fe8f5e750121a058a632ce3f9df44d5c0': 1}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "newDic = {}\n",
    "newList = []\n",
    "for i in listOfDicsOfDups: # {'dsdf':2}\n",
    "    obj = {}\n",
    "    myNum = numofDups[counter]\n",
    "    seqHash = list(i.keys())[0]\n",
    "    newDic.update({seqHash:myNum})\n",
    "    newList.append(newDic)\n",
    "    counter += 1\n",
    "    newDic = {}\n",
    "\n",
    "print(len(newList))\n",
    "print(newList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newList[0])\n",
    "print(newList[1])\n",
    "print(newList[2])\n",
    "print(newList[3])\n",
    "print(newList[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(newList[0])\n",
    "print(newList[1])\n",
    "print(newList[2])\n",
    "print(newList[3])\n",
    "print(newList[34])\n",
    "### output\n",
    "{'7930b7752c9b48d6cf08d8fd011db75fe8f5e750121a058a632ce3f9df44d5c0': 1}\n",
    "{'b6d31d96c81febb887c419a0bc15361e2f4d426388110814d2eaab042834cc87': 1}\n",
    "{'bbcefaf6463086437b6d2be1d8abf4d814386c2d0aa15f479c956002ca14d135': 1}\n",
    "{'90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb': 2}\n",
    "{'eb28c8a63f6d3dac50ad1ce8b0f0b56fb2081e41ebe4a5b7a20212041b33c6a3': 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorithm from process-protein ipynb\n",
    "1. cell 61: from result[0] labelMap result[1] labelseqHash\n",
    "1. from result[1] loop dictionary['seqHash'] add to a set\n",
    "1. set() does not accept duplicates, but it is unordered\n",
    "1. mySetUniqueSeqHash set 89832\n",
    "1. convert the set to list by list(mySet) to provide an index order\n",
    "1. listOfUnique 89832\n",
    "1. cell 64: create a list of dics duplicated as tuple('seqHash': 'xxxx', 'numOfDups': 19)\n",
    "1. or\n",
    "1. as {'XXXXXX': 19}\n",
    "1. or\n",
    "1. as {'XXXXX\" : []} to be able to add multiple label names hashes\n",
    "1. I decided for {'XXXXX': 19}\n",
    "1. listOfDicsOfDups\n",
    "1. cell 65: create a parallel list same length as listOfUnique and populate with zeros or None's otherwise it will complaint about adding to index out of bounds\n",
    "1. count number of duplicates by looping result[1] and adding one at the findIndex(i['seqHash']) in numOfDups list\n",
    "1. Finally, parallel loop listOfDicsOfDups and numOfDups to create a dic element type {'XXXXXXX': 3} total newList 89832\n",
    "1. Pending to confirm the correct mapping of seqHash to number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labelHash': 'bfba98cd8d86c34fc125975957ce1e6faeb612c76942eb6c34c19b00e670d168', 'seqHash': '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb'}\n",
      "{'labelHash': '75d470abc1a64d03778514694fa7792f4e1de60d7f0bf34e9bd190ff3b28f0e2', 'seqHash': '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb'}\n",
      "{'90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb': 2}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def findDuplicates(obj, item):\n",
    "    for i in obj:\n",
    "     if item == i['seqHash']:\n",
    "        print(i)\n",
    "def findDup(obj, item):\n",
    "   for i in obj:\n",
    "      if i.get(item):\n",
    "         print(i)\n",
    "         \n",
    "findDuplicates(result[1], '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb')\n",
    "\n",
    "print(findDup(newList, '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output\n",
    "{'labelHash': 'bfba98cd8d86c34fc125975957ce1e6faeb612c76942eb6c34c19b00e670d168', 'seqHash': '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb'}\n",
    "{'labelHash': '75d470abc1a64d03778514694fa7792f4e1de60d7f0bf34e9bd190ff3b28f0e2', 'seqHash': '90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb'}\n",
    "{'90e6b2a36ee7c3571d973fc78e49101eaf468cdff06cacecd31c53f015e277cb': 2}\n",
    "None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7930b7752c9b48d6cf08d8fd011db75fe8f5e750121a058a632ce3f9df44d5c0': 1}\n",
      "89832\n",
      "{'09cfb22627c69fe2a832df7f09fdcb80ddd44ac5875432677b03e54fd1d3e337': 102}\n",
      "{'3a96db023518af68d4879abed8848f635d5d655e9322d22a37100d32c89457a9': 101}\n",
      "{'41013e8a64849f25582af88ac47befcda56d5f1c46b6332f1400203f252ca3f5': 71}\n",
      "{'282fdbd8bf771ecef24ea29fe94f3cbe90f1f038891100bc44c7b84510488673': 62}\n",
      "{'e3ded293d60d16bdf71d3d5bfa526cafe04588ad9c155ebd1bec524a319885ab': 54}\n"
     ]
    }
   ],
   "source": [
    "print(newList[0])\n",
    "\n",
    "# my_list = [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]\n",
    "# my_list.sort(lambda x,y : cmp(x['name'], y['name']))\n",
    "\n",
    "# my_list = sorted(my_list, key=lambda k: k['name'])\n",
    "# key=lambda k: list(k.value())[0]\n",
    "# newlist = sorted(list_to_be_sorted, key=lambda d: d['name'])\n",
    "\n",
    "mySorted = sorted(newList, key=lambda k: list(k.values())[0] )\n",
    "print(len(mySorted))\n",
    "\n",
    "print(mySorted[-1])\n",
    "print(mySorted[-2])\n",
    "print(mySorted[-3])\n",
    "print(mySorted[-4])\n",
    "print(mySorted[-5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fox-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
