{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test suite \n",
    "\n",
    "## Procedure\n",
    "\n",
    "1. convert from FASTA to python dictionary {'label': '>NX_XXXX', 'XXXXXXXXX'}.gz\n",
    "1. *.labelmap.gz\n",
    "1. Map seqHash to labels as [ {'seqHash': 'iiiiiiiii', 'label': 'NX_xxxxx'}, .... ]\n",
    "1. *.labelseqHash.gz\n",
    "1. Hash into [{'labelHash':'iiiiiiii', 'seqHash':'iiiiiiii'}, ....]\n",
    "1. *.countdup.gz\n",
    "1. Extract unique sequences as [ {'seqHash' : countDups}, .... ] and\n",
    "1. [ { 'seqHash' : [ '>NX_XXXXX', '>NX_XXXX', ... ] }, ..... ]\n",
    "\n",
    "## Input\n",
    "\n",
    "1. https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/\n",
    "\n",
    "## Ouptut\n",
    "\n",
    "1. *.labelmap.gz\n",
    "1. *.labelseqhash.gz\n",
    "1. *.countDup.gz\n",
    "1. *.labelmap.labels.gz\n",
    "\n",
    "## Algorithm\n",
    "1. read gz files\n",
    "1. select labelmap and labelseqhas: read first ant last, count len\n",
    "1. check seqHash must be the same.\n",
    "\n",
    "## Interesting notes\n",
    "1. https://stackoverflow.com/questions/74325131/how-to-read-io-textiowrapper-multiple-times\n",
    "    1. Imagine your f object is nothing but a cursor. Once the cursor has ended readinig the file, you have to retake it to the beginning.\n",
    "    1. You can do this using the method seek with arguments (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test both ends from C:\\Users\\creeperpandatrex\\Documents\\1000genomes\\DATA\\38.p14.rna \n",
    "# GCF_000001405.40_GRCh38.p14_rna.fna.gz.labelmap\n",
    "# GLOBALS\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "from hashlib import sha256\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "inputPath = 'C:\\\\Users\\\\creeperpandatrex\\\\Documents\\\\1000genomes\\\\DATA\\\\38.p14.rna\\\\'\n",
    "labelmap = 'GCF_000001405.40_GRCh38.p14_rna.fna.gz.labelmap.gz'\n",
    "labelseqhash = 'GCF_000001405.40_GRCh38.p14_rna.fna.gz.labelseqhash.gz'\n",
    "\n",
    "\n",
    "firstLastMap = extractFirstLast(gzip.open(inputPath + labelmap, 'rt')) # <class '_io.TextIOWrapper'>\n",
    "firstLastHashes = extractFirstLast(gzip.open(inputPath + labelseqhash, 'rt')) # <class '_io.TextIOWrapper'>\n",
    "\n",
    "\n",
    "print(firstLastMap)\n",
    "print(firstLastHashes)\n",
    "\n",
    "# print2file(inputPath + inputFile + '.nonfasta', json.dumps(globalDictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def extractFirstLast(my):\n",
    "    with my as file:\n",
    "        print(type(file))\n",
    "        tmp = file.read()\n",
    "        print(type(tmp))\n",
    "        print(len(tmp))\n",
    "        print(len(json.loads(tmp)))\n",
    "        myinput = json.loads(tmp)\n",
    "    firstLast = []\n",
    "    firstLast.append(myinput[0])\n",
    "    firstLast.append(myinput[1])\n",
    "    firstLast.append(myinput[-2])\n",
    "    firstLast.append(myinput[-1])\n",
    "    return firstLast\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labelmap to json: first two, last two records and len\n",
    "\n",
    "class '_io.TextIOWrapper'>\n",
    "class 'str'>\n",
    "36807286\n",
    "185121\n",
    "class '_io.TextIOWrapper'>\n",
    "class 'str'>\n",
    "29989602\n",
    "185121\n",
    "\n",
    "## label labelhash\n",
    "1. [{'label': '>NM_000014.6 Homo sapiens alpha-2-macroglobulin (A2M), transcript variant 1, mRNA', \n",
    "1. '```labelHash```': '1a2af39c48aadc26d49ed5fb60e7d78bdf35c2b7088c23eaba1a633a75b1e8d6'}, \n",
    "1. {'label': '>NM_000015.3 Homo sapiens N-acetyltransferase 2 (NAT2), mRNA', \n",
    "1. '`labelHash`': 'ac84c06c0242b7b31874696926796c55a028681b8a224711fa3e6a64a864302c'}, \n",
    "1. {'label': '>XR_953308.2 PREDICTED: Homo sapiens uncharacterized LOC105370752 (LOC105370752), transcript variant X5, ncRNA', \n",
    "1. '`labelHash`': '44c8c543875e58b62a98c8f24186bf3c90107ab0d9154ed01ee77a0d82fabac1'}, \n",
    "1. {'label': '>XR_953308.2 PREDICTED: Homo sapiens uncharacterized LOC105370752 (LOC105370752), transcript variant X5, ncRNA',\n",
    "1. '`labelHash`': '44c8c543875e58b62a98c8f24186bf3c90107ab0d9154ed01ee77a0d82fabac1'}]\n",
    "\n",
    "## labelhash seqhash\n",
    "1. [{'```labelHash```': '1a2af39c48aadc26d49ed5fb60e7d78bdf35c2b7088c23eaba1a633a75b1e8d6', \n",
    "1. 'seqHash': '8cf4161a299b2d4b3efa87687f85b1f1468445dff5c9ff927018e6c9f2b58c2a'}, \n",
    "1. {'`labelHash`': 'ac84c06c0242b7b31874696926796c55a028681b8a224711fa3e6a64a864302c', \n",
    "1. 'seqHash': '76d2c9bc19bd552c3c11e09754a081881b17f1efeb320abb48637f362b430062'}, \n",
    "1. {'`labelHash`': '44c8c543875e58b62a98c8f24186bf3c90107ab0d9154ed01ee77a0d82fabac1', \n",
    "1. 'seqHash': '6f092438197c11aa7b0bec38191848bf05d0fe09a441382ec5335c054a67ea93'}, \n",
    "1. {'`labelHash`': '44c8c543875e58b62a98c8f24186bf3c90107ab0d9154ed01ee77a0d82fabac1', \n",
    "1. 'seqHash': '6f092438197c11aa7b0bec38191848bf05d0fe09a441382ec5335c054a67ea93'}]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fox-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
